<!DOCTYPE html>
<html>
<head>
<title>AI-powered drone beats human champion pilots</title>
<meta charset="UTF-8">
    <style>
        body {
            font-family: Arial, sans-serif;
        }
    </style>
    </head>
<body>
<h1>AI-powered drone beats human champion pilots</h1>
<p>Publication Date: 2023-08-30</p>
<p>Author: Ian Sample</p>
<p>Section: Technology</p>
<p>Tags: Technology, Artificial intelligence (AI), Drones (non-military), news</p>
<p>Article URL: <a href='https://www.theguardian.com/technology/2023/aug/30/ai-powered-drone-beats-human-champion-pilots' target='_blank'>https://www.theguardian.com/technology/2023/aug/30/ai-powered-drone-beats-human-champion-pilots</a></p>
<img src='https://media.guim.co.uk/867b341d884ee4b703d4056ae58aa085f5358439/100_0_2992_1795/500.jpg' alt='Article Image'>
<p>Having trounced humans at everything from chess and Go, to StarCraft and Gran Turismo, artificial intelligence (AI) has raised its game and defeated world champions at a real-world sport. The latest mortals to feel the sting of AI-induced defeat are three expert drone racers who were beaten by an algorithm that learned to fly a drone around a 3D race course at breakneck speeds without crashing. Or at least not crashing too often. Developed by researchers at the University of Zurich, the Swift AI won 15 out of 25 races against world champions and clocked the fastest lap on a course where drones reach speeds of 50mph (80km/h) and endure accelerations up to 5g, enough to make many people black out. “Our result marks the first time that a robot powered by AI has beaten a human champion in a real physical sport designed for and by humans,” said Elia Kaufmann, a researcher who helped to develop Swift. First-person view drone racing involves flying a drone around a course dotted with gates that must be passed through cleanly to avoid a crash. The pilots see the course via a video feed from a camera mounted on the drone. Writing in Nature, Kaufmann and his colleagues describe a series of head-to-head races between Swift and three champion drone racers, Thomas Bitmatta, Marvin Schäpper and Alex Vanover. Before the contest, the human pilots had a week to practise on the course, while Swift trained in a simulated environment that contained a virtual replica of the course. Swift used a technique called deep reinforcement learning to find the optimal commands to hurtle around the circuit. Because the method relies on trial and error, the drone crashed hundreds of times in training, but since it was a simulation the researchers could simply restart the process. During a race, Swift sends video from the drone’s onboard camera to a neural network that detects the racing gates. This information is combined with readings from an inertial sensor to estimate the drone’s position, orientation and speed. These estimates are then fed to a second neural network that works out what commands to send to the drone. Analysis of the races showed that Swift was consistently faster at the start of a race and pulled tighter turns than the human pilots. The quickest lap from Swift came in at 17.47 seconds, half a second faster than the fastest human pilot. But Swift was not invincible. It lost 40% of its races against humans and crashed several times. The drone, it seemed, was sensitive to changes in the environment such as lighting. The races left the world champions with mixed feelings. “This is the start of something that could change the whole world. On the flip side, I’m a racer, I don’t want anything to be faster than me,” said Bitmatta. And as Schäpper noted: “It feels different racing against a machine, because you know that the machine doesn’t get tired.” A key advance is that Swift can cope with real world challenges such as aerodynamic turbulence, camera blur and changes in illumination, which can confuse systems that attempt to follow a pre-computed trajectory. Kaufmann said the same approach could help drones search for people in burning buildings or conduct inspections of large structures such as ships. The military has an intense interest in AI-powered drones, but were not convinced that the latest work would have major implications for warfare. Dr Elliot Winter, a senior lecturer in international law at Newcastle Law School, said: “We must be careful not to assume that advancements such as these can easily be transplanted into a military context for use in military drones or autonomous weapons systems which are involved in critical processes such as target selection.” Alan Winfield, a professor of robot ethics, said while AI had “inevitable” military uses, he was unsure how the latest work could benefit the military beyond perhaps having flocks of drones that follow a plane in close formation. Kaufmann was similarly sceptical. “Almost all drones are used in wide-open battlefields and are either used for reconnaissance or as weapons against slow-moving and stationary targets,” he said.</p>
</body>
</html>