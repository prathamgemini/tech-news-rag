<!DOCTYPE html>
<html>
<head>
<title>‘AI can teach us a lot’: scientists say cats’ expressions richer than imagined and aim to translate them</title>
<meta charset="UTF-8">
    <style>
        body {
            font-family: Arial, sans-serif;
        }
    </style>
    </head>
<body>
<h1>‘AI can teach us a lot’: scientists say cats’ expressions richer than imagined and aim to translate them</h1>
<p>Publication Date: 2023-11-04</p>
<p>Author: Nicola Davis</p>
<p>Section: Technology</p>
<p>Tags: Artificial intelligence (AI), Animal behaviour, Biology, features</p>
<p>Article URL: <a href='https://www.theguardian.com/technology/2023/nov/04/scientists-turn-to-ai-for-help-translate-animal-vocal-physical-cues' target='_blank'>https://www.theguardian.com/technology/2023/nov/04/scientists-turn-to-ai-for-help-translate-animal-vocal-physical-cues</a></p>
<img src='https://media.guim.co.uk/152ba51dae78632efd524c0925bdea8a65e24392/0_358_3600_2160/500.jpg' alt='Article Image'>
<p>If an unexpected meow, peculiar pose, or unusual twitch of the whiskers leaves you puzzling over what your cat is trying to tell you, artificial intelligence may soon be able to translate. Scientists are turning to new technology to unpick the meanings behind the vocal and physical cues of a host of animals. “We could use AI to teach us a lot about what animals are trying to say to us,” said Daniel Mills, a professor of veterinary behavioural medicine at the University of Lincoln. Previous work, including by Mills, has shown that cats produce a variety of facial expressions when interacting with humans, and this week researchers revealed felines have a range of 276 facial expressions when interacting with other cats. “However, the facial expressions they produce towards humans look different from those produced towards cats,” said Dr Brittany Florkiewicz, an assistant professor of psychology at Lyon College in Arkansas who co-authored the new work. Mills said the latest research highlighted the complexity of feline facial manoeuvres, adding that new technology could help to unpick them. “As this paper suggests, there is a much greater richness in cat expressions than we appreciate and what AI is good at is classifying images,” he said. One approach, said Mills, was to teach AI to identify specific features such as ear position, which is already known to be important for certain emotions. Another more modern approach is to allow AI to come up with its own rules for classification. While that brings its own challenges, Mills said it could also offer fresh insights. “It could highlight the rules it uses to distinguish data sets, which can show us where to look for the best way to distinguish certain expressions.” Mills and colleagues are already attempting to use AI to try to tease out certain emotional states from facial expressions in cats, dogs and horses. He said there was no shortage of videos to work with – a truth universally acknowledged by anyone who has spent time on YouTube. As well as offering us new ways to understand what our pets are trying to communicate, Mills noted AI could be used for animal welfare, for example to screen the faces of cows for signs of pain as they troop in for milking. “In effect, they can have a daily health check of how happy they are,” he said. Among those looking at such applications is Dr Elodie Briefer, an associate professor of ecology and evolution at the University of Copenhagen. Her research has shown AI can be trained to classify pig vocalisations to distinguish between pigs that are happy and those that are not. The idea, Briefer said, was that such tools could be used on farms to track the welfare of the animals. “During an increase in negative calls, the farmer can check what’s going on, or if he or she implements some new measures like enrichment he or she can see if there is increasing positive calls, for example,” she said. Briefer added that her team were hoping in future work to couple such findings with AI-based analysis of pigs’ body postures and expressions. “You can get much more information if you use AI on both vocalisations and videos to study facial expressions and body movements,” she said. There are wider implications of using AI to understand animal communication, including to aid conservation. Mills said the technology could also provide insights into more fundamental biology and psychology, including understanding the origins of some human traits. Briefer agreed. Among other work, her team is using AI to classify vocalisations in animals such as zebras, white rhinos and parakeets to explore how they communicate. She also said researchers were using AI to explore the size of animals’ call repertoires and how these calls are combined in a sort of rudimentary syntax to convey information. “That could help us to get to know how did we come up with such huge language skills compared with our closest relatives,” she said. Prof Christian Rutz, from the University of St Andrews, also said the technology had great potential. “Machine-learning methods will transform our understanding of animal communication, creating valuable opportunities to improve wildlife conservation and animal welfare,” he said. But, as Rutz and his colleagues have recently noted, there could be potential pitfalls too – not least should researchers attempt communication with animals in their own “language” before such signals are fully understood. “We urgently need to agree on ethical standards for this kind of work to prevent unintended harm or misuse,” he said.</p>
</body>
</html>