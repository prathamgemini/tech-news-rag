<!DOCTYPE html>
<html>
<head>
<title>Google DeepMind testing ‘personal life coach’ AI tool</title>
<meta charset="UTF-8">
    <style>
        body {
            font-family: Arial, sans-serif;
        }
    </style>
    </head>
<body>
<h1>Google DeepMind testing ‘personal life coach’ AI tool</h1>
<p>Publication Date: 2023-08-17</p>
<p>Author: Hibaq Farah</p>
<p>Section: Technology</p>
<p>Tags: Artificial intelligence (AI), Google, DeepMind, news</p>
<p>Article URL: <a href='https://www.theguardian.com/technology/2023/aug/17/google-deepmind-testing-personal-life-coach-ai-tool' target='_blank'>https://www.theguardian.com/technology/2023/aug/17/google-deepmind-testing-personal-life-coach-ai-tool</a></p>
<img src='https://media.guim.co.uk/4f5a645fc459c27cf1563fa0cb1cfd11d656d6b4/0_238_4000_2400/500.jpg' alt='Article Image'>
<p>The next time you lie in bed and absent-mindedly ask your old friend Google for a piece of life advice, don’t be surprised if it speaks back to you. DeepMind, the tech firm’s artificial intelligence arm, has announced it is testing a new tool that could soon become a “personal life coach”. The project will use generative AI to perform at least 21 different types of personal and professional tasks, including life advice, ideas, planning instructions and tutoring tips, according to documents seen by the New York Times. It is also being tested for how well the assistant can answer intimate questions about people’s lives. One example of a prompt a user could one day ask the chatbot was a challenging personal question about how to go about telling a close friend who is having a destination wedding that you cannot afford to go. The tool is said to have an idea-creation feature that will provide user suggestions or recommendations based on different situations. It can also teach or improve skills, such as running, and provide users with meal and workout plans. AI experts have warned about the dangers of chatbots, and there have been ethical concerns about the relationships humans will have with chatbots, amid growing calls for regulation and laws to combat the rapid development of AI. Dr Christian Guttmann, AI scientist and vice-president of engineering, decisioning and AI at Pegasystems, said: “This development is a natural progression of how AI is implemented in our daily lives. And indeed, utilising AI has already been successfully used in other environments for many years in areas which are sensitive and where humans actually prefer to ask an AI for advice.” He added: “It is of course important to take a responsible approach to building these relationships between humans and AI systems to ensure that advice that is given to a person is safe and sound and in line with what a professional would advise.” Earlier this year, Google merged with DeepMind to create Google DeepMind, bringing together two research groups in the AI field: Google Researcher’s Brain team and DeepMind. In a blog post in April announcing the merge, Sundar Pichai, CEO of Google and Alphabet, said: “To ensure the bold and responsible development of general AI, we’re creating a unit that will help us build more capable systems more safely and responsibly.” A Google DeepMind spokesperson said: “We have long worked with a variety of partners to evaluate our research and products across Google, which is a critical step in building safe and helpful technology. At any time there are many such evaluations ongoing. Isolated samples of evaluation data are not representative of our product road map.”</p>
</body>
</html>