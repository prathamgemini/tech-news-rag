<!DOCTYPE html>
<html>
<head>
<title>Fake AI-generated image of explosion near Pentagon spreads on social media</title>
<meta charset="UTF-8">
    <style>
        body {
            font-family: Arial, sans-serif;
        }
    </style>
    </head>
<body>
<h1>Fake AI-generated image of explosion near Pentagon spreads on social media</h1>
<p>Publication Date: 2023-05-22</p>
<p>Author: Abené Clayton</p>
<p>Section: Technology</p>
<p>Tags: Artificial intelligence (AI), US military, Social media, news</p>
<p>Article URL: <a href='https://www.theguardian.com/technology/2023/may/22/pentagon-ai-generated-image-explosion' target='_blank'>https://www.theguardian.com/technology/2023/may/22/pentagon-ai-generated-image-explosion</a></p>
<img src='https://media.guim.co.uk/44a2bb26fb4fbdefe3a3e0026acec69495fb7717/0_180_5396_3238/500.jpg' alt='Article Image'>
<p>An AI-generated image that appeared to show an explosion next to a building in the Pentagon complex circulated on social media platforms on Monday, in the latest incident to highlight concerns over misinformation generated by AI. The image of a tall, dark gray plume of smoke quickly spread on Twitter, including through shares by verified accounts. It remains unclear where it originated. The US Department of Defense has confirmed that the image was a fake. Still, its virality appears to have caused a brief dip in the stock market, CNN reports. In a tweet, the fire department for Arlington, Virginia, outside Washington, said that it was aware of social media reports about the explosion but that there was no threat to the public. OSINTdefender, a Twitter page that shares news about international military conflicts and has over 336,000 followers, was one of the verified pages that shared the photo. The page’s owner apologized for spreading misinformation and said the incident was an example of how “easily these sort of images can be used to manipulate the information space and how dangerous this could be in the future”. The image is one of several AI-generated ones that have gone viral in recent weeks. Recent examples include one of the pope wearing a fashion-forward white long puffer coat and a black and white photorealistic image that won a prize from the Sony World Photography Awards. The German artist who created the prize-winning image said he applied to the awards as a “cheeky monkey” to find out if competitions would be prepared for AI images to enter. He ultimately rejected the award. The incident also once again spotlighted verification challenges on Twitter, since the platform overhauled its subscription service, Twitter Blue. Up until last month, the platform gave out blue check badges to users whose identity the platform had verified. Under the new Twitter Blue program rolled out last month, however, individuals can pay $8 a month for a blue check mark. Concerns about accounts impersonating public figures, government officials and news sites have grown since the change.</p>
</body>
</html>