<!DOCTYPE html>
<html>
<head>
<title>EU urged to protect grassroots AI research or risk losing out to US</title>
<meta charset="UTF-8">
    <style>
        body {
            font-family: Arial, sans-serif;
        }
    </style>
    </head>
<body>
<h1>EU urged to protect grassroots AI research or risk losing out to US</h1>
<p>Publication Date: 2023-05-04</p>
<p>Author: Alex Hern</p>
<p>Section: Technology</p>
<p>Tags: Artificial intelligence (AI), Computing, European Union, Europe, news</p>
<p>Article URL: <a href='https://www.theguardian.com/technology/2023/may/04/eu-urged-to-protect-grassroots-ai-research-or-risk-losing-out-to-us' target='_blank'>https://www.theguardian.com/technology/2023/may/04/eu-urged-to-protect-grassroots-ai-research-or-risk-losing-out-to-us</a></p>
<img src='https://media.guim.co.uk/66c41cbf46af3212c38348e96e64d2c6e09bbbfc/0_48_4351_2612/500.jpg' alt='Article Image'>
<p>The EU has been warned that it risks handing control of artificial intelligence to US tech firms if it does not act to protect grassroots research in its forthcoming AI bill. In an open letter coordinated by the German research group Laion, or Large-scale AI Open Network, the European parliament was told that “one-size-fits-all” rules risked eliminating open research and development. “Rules that require a researcher or developer to monitor or control downstream use could make it impossible to release open-source AI in Europe,” which would “entrench large firms” and “hamper efforts to improve transparency, reduce competition, limit academic freedom, and drive investment in AI overseas”, the letter says. It adds: “Europe cannot afford to lose AI sovereignty. Eliminating open-source R&amp;D will leave the European scientific community and economy critically dependent on a handful of foreign and proprietary firms for essential AI infrastructure.” The largest AI efforts, by companies such as OpenAI and Google, are heavily controlled by their creators. It is impossible to download the model behind ChatGPT, for instance, and the paid-for access that OpenAI provides to customers comes with a number of restrictions, legal and technical, on how it can be used. By contrast, open-source AI efforts involve creating an AI model and then releasing it for anyone to use, improve or adapt as they see fit. “We are working on open-source AI because we think that sort of AI will be more safe, more accessible and more democratic,” said Christoph Schuhmann, the lead of Laion. Unlike his peers at US AI businesses, who control billion-dollar organisations and frequently have a personal wealth in the hundreds of millions, Schuhmann is a volunteer in the AI world. “I’m a tenured high-school teacher in computer science, and I’m doing everything for free as a hobby, because I’m convinced that we will have near-human-level AI within the next five to 10 years,” he said. “This technology is a digital superpower that will change the world completely, and I want to see my kids growing up in a world where this power is democratised.” Laion’s work has already been influential. The group, which has received funding from the UK startup Stability AI, focuses on producing open datasets and models for other AI researchers to train their own systems on. One database, of almost 6bn labelled images collected from the internet, underpins the popular Stable Diffusion image-generating AI, while another model, called Openclip, is a recreation of a private system built by OpenAI that can be used to label images. Such work can prove controversial. Stable Diffusion, for instance, can be used to generate explicit, obscene and disturbing images, while Laoin’s image database has been criticised for not respecting the rights of the creators whose work is included. Those criticisms are what has led bodies such as the EU to consider holding companies responsible for what their AI systems do – but such regulation would render it impossible to release systems to the public at large, which Schuhmann says would destroy the continent’s ability to compete. Instead, he argues that the EU should actively back open-source research with its own public facilities, to “accelerate the safe development of next-generation models under controlled conditions with public oversight and following European values”. Other groups such as the Tony Blair Institute have called for the UK to do similarly, and fund the creation of a “BritGPT” to bring future AI under public control. Schuhmann and his co-signatories are part of a growing chorus of AI experts hitting back at calls to slow down development. At a conference in Florence discussing the future of the EU, many lined up to decry a recent letter signed by Elon Musk and others calling for a pause on the creation of giant AIs for at least six months. Sandra Wachter, a professor at the Oxford internet institute at Oxford University, said: “The hype around large language models, the noise is deafening. Let’s focus on who is screaming, who is promising that this technology will be so disruptive: the people who have a vested financial interest that thing is going to be successful. So don’t separate the message from the speaker.” She told the audience at the European University Institute’s State of the Union event that the world had seen this cycle of hype and fear before with the web, cryptocurrency and driverless cars. “Every time we see something like this happens, it’s like: ‘Oh my God, the world will never be the same.’” She urged against haste in regulation, warning that “angst and panic is not a good political adviser”, and said the focus should be on talking to people in health, finance and education about their opinions.</p>
</body>
</html>