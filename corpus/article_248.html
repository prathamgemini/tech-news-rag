<!DOCTYPE html>
<html>
<head>
<title>Nick Clegg defends release of open-source AI model by Meta</title>
<meta charset="UTF-8">
    <style>
        body {
            font-family: Arial, sans-serif;
        }
    </style>
    </head>
<body>
<h1>Nick Clegg defends release of open-source AI model by Meta</h1>
<p>Publication Date: 2023-07-19</p>
<p>Author: Dan Milmo</p>
<p>Section: Technology</p>
<p>Tags: Artificial intelligence (AI), Meta, Nick Clegg, Facebook, Computing, Social networking, Technology sector, news</p>
<p>Article URL: <a href='https://www.theguardian.com/technology/2023/jul/19/nick-clegg-defends-release-open-source-ai-model-meta-facebook' target='_blank'>https://www.theguardian.com/technology/2023/jul/19/nick-clegg-defends-release-open-source-ai-model-meta-facebook</a></p>
<img src='https://media.guim.co.uk/31e225fa75f875781b06e0fc3c56b3b3aabbeb5f/0_135_3200_1921/500.jpg' alt='Article Image'>
<p>Nick Clegg has defended the release of an open-source artificial intelligence model by Mark Zuckerberg’s Meta, as he claimed that “hype” about AI’s dangers was running ahead of the technology’s development. The president of global affairs at Meta and former UK deputy prime minister spoke on Wednesday after the company said it was opening access to its new large language model (LLM), Llama 2, which will be free for research and commercial use. LLMs are trained on vast amounts of data and underpin generative AI products such as the ChatGPT chatbot. Some experts have warned that making AI models open source – or freely available to use and adapt for unique purposes – could lead to the technology being used for malicious purposes. Speaking on BBC Radio 4’s Today programme, Clegg said: “My view is that the hype has somewhat run ahead of the technology. I think a lot of the existential warnings relate to models that don’t currently exist, so-called super-intelligent, super-powerful AI models – the vision where AI develops an autonomy and agency on its own, where it can think for itself and reproduce itself. “The models that we’re open-sourcing are far, far, far short of that. In fact, in many ways they’re quite stupid.” However, one AI expert compared Meta’s open-source move to handing over the secrets to making a nuclear weapon. Dame Wendy Hall, regius professor of computer science at the University of Southampton, said there were questions over whether the tech industry could be trusted to self-regulate LLMs, with the problem looming even larger for open-source models. “It’s a bit like giving people a template to build a nuclear bomb,” she told Today. Clegg said Meta had 350 people “stress-testing” its models over several months to check for any potential problems, and Llama 2 was safer than any other open-source large language models available. He said “it’s not as if we’re at a T-junction” where companies can “choose to open source or not”, adding: “Models are being open-sourced all the time already.” While Clegg said he strongly believed AI should be regulated, he added that that “doesn’t mean that every single AI model should be open-sourced”, adding that Meta would not be releasing a voice-generating model, called Voicebox, to the public. Referring to Llama 2, Clegg said the “wisdom of crowds” would make AI models safer rather than leaving them in the “clammy hands” of technology multinationals. “Crucially, you take it out of the … clammy hands of the big tech companies, which are currently the only companies that have either the computing power or the vast reservoirs of data to build these models in the first place,” he said. In May, Google was warned by one of its engineers that it could be beaten in the AI race by commonly available open-source technology. “The uncomfortable truth is, we aren’t positioned to win this arms race and neither is [ChatGPT developer] OpenAI. While we’ve been squabbling, a third faction has been quietly eating our lunch,” the engineer wrote, referring to open-source AI.</p>
</body>
</html>