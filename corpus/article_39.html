<!DOCTYPE html>
<html>
<head>
<title>We need AI to help us face the challenges of the future</title>
<meta charset="UTF-8">
    <style>
        body {
            font-family: Arial, sans-serif;
        }
    </style>
    </head>
<body>
<h1>We need AI to help us face the challenges of the future</h1>
<p>Publication Date: 2023-05-12</p>
<p>Author: Unknown</p>
<p>Section: Technology</p>
<p>Tags: Artificial intelligence (AI), Consciousness, Computing, Climate crisis, Silicon Valley, letters</p>
<p>Article URL: <a href='https://www.theguardian.com/technology/2023/may/12/we-need-ai-to-help-us-face-the-challenges-of-the-future' target='_blank'>https://www.theguardian.com/technology/2023/may/12/we-need-ai-to-help-us-face-the-challenges-of-the-future</a></p>
<img src='https://media.guim.co.uk/597d5f6734c16144721d0597b01c71b97101cb20/0_115_4000_2399/500.jpg' alt='Article Image'>
<p>Naomi Klein’s article about the dangers of generative AI makes many valid points about the economic and social consequences of the new technology (AI machines aren’t ‘hallucinating’. But their makers are, 8 May). But her choice of language about how to describe the mistakes that the new AI makes seems to suggest she is committed mainly to providing an ideological interpretation of the new technology. Saying that mistakes are the results of glitches in the code rather than the tech hallucinating suggests the simulation is a simple one, involving a kind of power of the false rather than a more complex one that allows the possibility of some form of fabulation. This is important because it means that the technology can’t be seen simply as a control technology, like nuclear fusion or self-driving cars, but instead indicates a switch to an adaptive form of technology, ie, ones that are based on adapting what is already out there rather than trying to reinvent what exists, as in some form of innovation. Obviously, climate change will require more of the adaptive kinds of technology, like reusable space rockets and wind farms, because control technologies are very resource heavy and tend to cause a lot of collateral damage. Terry Price London • Naomi Klein is right to voice scepticism about the claims made for generative AI. As its development coincides with endgame capitalism, a minimum requirement for its effective governance must be that those responsible for its programming are truly representative, not only of humanity as a whole but the living planet. Rather than a group of white, male, wealthy individuals developing AI in their image, we need to ensure that indigenous wisdom, the aspirations of future generations drawn from all continents and those able to identify the impact of potential decisions and actions on our ecosystems all need to participate in the design of these AI developments. Without such input, all such AI will do is exacerbate our demise: with these contributions, it may yet avert it. Surely this is an issue that is too important to be left to Silicon Valley to self-determine. Dave Hunter Bristol • The real danger of AI systems arises from the fact that these systems have no actual intelligence and so cannot distinguish whether the results they produce are correct or not. ChatGPT produces intelligent results in the midst of a whole lot of other results which, to our human intelligence, are simply ridiculous. This doesn’t matter too much because we simply laugh at and discard the ridiculous results. But when these AI systems are controlling cars and planes, where the ridiculous results are a danger to life and can’t just be “discarded”, the consequences could be catastrophic. The artificial neural networks producing AI are bandied about as emulators of the brain. But in spite of decades of dedicated research, neural networks have just 10 to 1,000 neurons, whereas the human brain has 86bn of them. No wonder that an AI system has no way of knowing whether it has produced an intelligent (by human standards) result. Charles Rowe Wantage, Oxfordshire • It is understandable that there is concern over the effect that AI will have on our future, but I am equally concerned about the damage that humans will do if we’re left in charge (Why the godfather of AI fears for humanity, 5 May). Would an AI system really have dealt with the Covid pandemic worse than Boris Johnson? Would it have allowed our planet to get so close to the precipice of climate catastrophe? Geoffrey Hinton believes that once AI is more intelligent than us, it will inevitably take charge, and perhaps he is right to be concerned. On the other hand, it might be just what we need. Ben Chester Stroud, Gloucestershire • Have an opinion on anything you’ve read in the Guardian today? Please email us your letter and it will be considered for publication in our letters section.</p>
</body>
</html>