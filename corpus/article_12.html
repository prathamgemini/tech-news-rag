<!DOCTYPE html>
<html>
<head>
<title>UK competition watchdog launches review of AI market</title>
<meta charset="UTF-8">
    <style>
        body {
            font-family: Arial, sans-serif;
        }
    </style>
    </head>
<body>
<h1>UK competition watchdog launches review of AI market</h1>
<p>Publication Date: 2023-05-04</p>
<p>Author: Dan Milmo</p>
<p>Section: Technology</p>
<p>Tags: Artificial intelligence (AI), ChatGPT, Competition and Markets Authority, Computing, Regulators, Data and computer security, Privacy, news</p>
<p>Article URL: <a href='https://www.theguardian.com/technology/2023/may/04/uk-competition-watchdog-launches-review-ai-market-artificial-intelligence' target='_blank'>https://www.theguardian.com/technology/2023/may/04/uk-competition-watchdog-launches-review-ai-market-artificial-intelligence</a></p>
<img src='https://media.guim.co.uk/a1a620a2b5ce357173f64fe4fb7907fff0d2fb22/120_0_3600_2160/500.jpg' alt='Article Image'>
<p>The UK competition watchdog has fired a shot across the bows of companies racing to commercialise artificial intelligence technology, announcing a review of the sector as fears grow over the spread of misinformation and major disruption in the jobs market. As pressure builds on global regulators to increase their scrutiny of the technology, the Competition and Markets Authority said it would look at the underlying systems, or foundation models, behind AI tools such as ChatGPT. The initial review, described by one legal expert as a “pre-warning” to the sector, will publish its findings in September. In the US, the vice-president, Kamala Harris, has invited the chief executives of the leading AI firms ChatGPT, Microsoft and Google-owner Alphabet to the White House on Thursday to discuss how to deal with the safety concerns around the technology. The Federal Trade Commission, which oversees competition in the US, has signalled it is also watching closely, saying this week its staff were “focusing intensely” on how companies might choose to use AI technology, in ways that could have “actual and substantial impact on consumers”. Meanwhile, the Italian data watchdog lifted a temporary ban on ChatGPT last week after OpenAI addressed concerns over data use and privacy. The government’s outgoing scientific adviser, Sir Patrick Vallance, has urged ministers to “get ahead” of the profound social and economic changes that could be triggered by AI, saying the impact on jobs could be as big as that of the Industrial Revolution. On Monday, the boss of the computing firm IBM revealed he expected to pause hiring in roles that could be replaced by AI in the coming years, saying as many as a third of the company’s non-customer facing jobs – about 7,800 roles – could be affected. The disruption has spread to stock markets, with hundreds of millions of pounds wiped from the share price of the UK education company Pearson this week, after Chegg, a US provider of online help to students for writing and maths assignments, revised its financial forecasts and said ChatGPT was affecting customer growth. The CMA chief executive, Sarah Cardell, said AI had the potential to “transform” the way businesses and consumers competed, but that consumers must be protected. “AI has burst into the public consciousness over the past few months but has been on our radar for some time,” said Cardell. “It’s crucial that the potential benefits of this transformative technology are readily accessible to UK businesses and consumers while people remain protected from issues like false or misleading information.” ChatGPT and Google’s rival Bard service are prone to delivering false information in response to users’ prompts, while the anti-misinformation outfit NewsGuard said this week that chatbots pretending to be journalists were running almost 50 AI-generated “content farms”. The CMA review will look at how the markets for foundation models could evolve, what opportunities and risks there are for consumers and competition, and formulate “guiding principles” to support competition and protect consumers. The major players in AI are Microsoft, OpenAI – in which Microsoft is an investor – and Alphabet, which owns a world-leading AI business in UK-based DeepMind, while leading AI startups include Anthropic and Stability AI, the British company behind Stable Diffusion. The announcement of an initial review was a “pre-warning” to firms developing AI models, said Alex Haffner, competition partner at the UK law firm Fladgate. “Given the direction of regulatory travel at the moment and the fact the CMA is deciding to dedicate resource to this area, its announcement must be seen as some form of pre-warning about aggressive development of AI programmes without due scrutiny being applied.” The watchdog has been asked by ministers to consider how the development and use of AI can be supported against five principles: safety, transparency, fairness, accountability, and the ability of newcomers to challenge established players in AI. Verity Egerton-Doyle, the UK co-head of technology at Linklaters law firm, said the CMA had seen an opportunity to “lead the global debate on these issues”. “It is not surprising the CMA has decided to look at AI,” she said. “It has been known for some time that the CMA is keen to skill up and understand what role there is for competition law in this important new area”.</p>
</body>
</html>