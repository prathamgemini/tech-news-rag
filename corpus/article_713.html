<!DOCTYPE html>
<html>
<head>
<title>Mark Zuckerberg and Snap CEO Evan Spiegel apologize to families of online harm victims at Senate hearing – as it happened</title>
<meta charset="UTF-8">
    <style>
        body {
            font-family: Arial, sans-serif;
        }
    </style>
    </head>
<body>
<h1>Mark Zuckerberg and Snap CEO Evan Spiegel apologize to families of online harm victims at Senate hearing – as it happened</h1>
<p>Publication Date: 2024-01-31</p>
<p>Author: Kari Paul</p>
<p>Section: Technology</p>
<p>Tags: Technology, Meta, Snapchat, Social media, X, Internet, Facebook</p>
<p>Article URL: <a href='https://www.theguardian.com/technology/live/2024/jan/31/congress-social-media-hearing-tiktok-meta-twitter-child-safety-latest-updates' target='_blank'>https://www.theguardian.com/technology/live/2024/jan/31/congress-social-media-hearing-tiktok-meta-twitter-child-safety-latest-updates</a></p>
<img src='https://media.guim.co.uk/c17e2bc8bfebe792d40372563290069a43e52638/717_146_3116_1870/500.jpg' alt='Article Image'>
<p>After five tech executives faced four hours of intensive questioning from Congress members, the Senate judiciary hearing on “Big Tech and the Online Child Sexual Exploitation Crisis” has come to an end. Executives in attendance were Mark Zuckerberg of Meta, Linda Yaccarino of X (formerly Twitter), Shou Zi Chew of TikTok, Evan Spiegel of Snap, and Jason Citron of Discord. In closing statements, Senate chair Dick Durbin called for meaningful bipartisan legislation to address the “crisis” of childhood sexual exploitation online. “Businesses exist by and large to be profitable, and I think we have to get behind that and say, ‘profitability at what cost?’” he said. Here are the key events from the day: Parents of children who died by suicide after experiencing online harms packed the Senate for the hearing on Wednesday. Senator Lindsey Graham said the event drew “the largest [audience] I’ve seen in this room”. Opening statements in the hearing included voices of children and parents of children affected. In opening statements, executives enumerated tools on their platforms meant to protect children and give parents more control over the user experience. Senators challenged these assertions in their questioning, stating that the measures are ineffective and insufficient. In his first remarks, Meta CEO Mark Zuckerberg cast doubt on the relationship between social media use and a decline in mental health. “The existing body of scientific work has not shown a causal link between using social media and young people having worse mental health,” he said. Senators repeatedly targeted Section 230, a legal protection that shields social media firms from liability for content posted on their platforms. They promoted a number of bills that would take aim at these protections, including the Kids Online Safety Act (Kosa). X, formerly Twitter, became the first tech firm to publicly endorse the Stop CSAM Act, a bill introduced by Sen. Dick Durbin (D-IL) that would remove legal immunity for civil claims against internet companies over child sex abuse material. CEO Linda Yaccarino also announced support of Kosa, joining Snapchat parent company Snap. Zuckerberg apologized directly to families of online harm victims in Senate hearing, standing from his seat and turning to a crowd holding photos of children who have died by suicide after experiencing online harms. “I’m sorry for everything you have all been through,” he said. Snap CEO Evan Spiegel also apologized to families, though he did not turn to face them as Zuckerberg did. In response to questions about children who have died from drugs bought on Snapchat, he said: “I’m so sorry that we have not been able to prevent these tragedies. We work very hard to block all search terms related to drugs on our platform”. The Guardian view on online child protection: the web needs more health and safety The Senate hearing over alleged online harms to children has come to a close. In final statements, chairman Durbin said that America has reached “a moment of reckoning” regarding the unchecked power of Big Tech and that legislation must be passed to rein it in. “As parents and grandparents we know what daughters and sons and others are going through they cannot cope,” he said. “They cannot handle this issue on their own. They’re counting on us, as much as they’re counting on the industry, to do the responsible thing. “ Senator Blackburn took a hard stance against Mark Zuckerberg, asking why intentionally predatory content does not violate platform standards, citing a June 2023 article from the Wall Street Journal investigating how Instagram connects “a vast pedophile network”. The report revealed that Instagram was recommending hashtags for children to sell CSAM of themselves. Blackburn called Meta “the largest sex trafficking organization in the world”. Zuckerberg responded agitatedly, saying: “Senator, that’s ridiculous”. Blackburn closed by stating Meta and other companies have an obligation to work with Congress, stating that they have not complied voluntarily in the past. “You have an army of lawyers who fight us on any bipartisan legislation,” she said. “Are you going to stop lobbying against the legislation considered in this hearing? You need to come to the table – kids are dying.” In her line of questioning, Senator Marsha Blackburn cited an internal email at Meta revealed as part of a lawsuit from US attorneys general that stated product teams that referred to younger users in terms of their lifetime value of being “roughly $270 per teenager”. She acknowledge teenagers in the crowd for the hearing wearing shirts that read “I’m worth more than $270,” which elicited applause from the crowd. Sen. Laphonza Butler (D-CA) asked Snap CEO Evan Spiegel: “There are a number of parents whose children have been able to access illegal drugs on your platform. What do you say to those parents?” Parents over more than 60 teenagers filed suit in late 2023 against Snap for allegedly facilitating their children’s acquisition of drugs that were used in overdoses. Unlike Zuckerberg, Spiegel did not turn to face the families in attendance. He said, “I’m so sorry that we have not been able to prevent these tragedies. We work very hard to block all search terms related to drugs on our platform.” He highlighted Snapchat’s education efforts to convey the message of “one pill can kill”. His full apology below: We work very hard to block all search terms related to drugs from our platform. We proactively look for and detect drug-related content. We remove it from our platform, preserve the evidence, and then we refer it to law enforcement for action. We’ve worked together with nonprofits and with families on education campaigns, because the scale the fentanyl epidemic is extraordinary. Over 100,000 people lost their lives last year and we believe people need to know that one pill can kill. That campaign was viewed more than 260 million times on Snapchat. The hearing is back on, starting with questioning from Senator John Neely Kennedy who said the reforms and tools created by social media firms are not sufficient and action from Congress is needed. “Your companies are going to need the government’s help,” he said. “Any reforms you do on your own are like paint on rotten wood.” Meta is the world’s ‘single largest marketplace for paedophiles’, says New Mexico attorney general In an interview with the Guardian, New Mexico’s top legal official Raúl Torrez talks about taking Facebook and Instagram’s parent company to court. In December 2023, Torrez launched a major lawsuit against Meta, claiming that the company has allowed its social media platforms to become marketplaces for child predators. Torrez tells the Guardian he believes that what his own investigation has already uncovered is “just the tip of the iceberg when it comes to how widespread and well known this problem was inside the company”. He said he expects further details to emerge about its knowledge of child sexual exploitation on its platforms. The hearing is taking a 10-minute recess. More updates soon … Republican senator Tom Cotton used his time on the floor of the Senate hearing to fire off a series of xenophobic questions to TikTok CEO Shou Zi Chew. Echoing a prior line of questioning from Senator Ted Cruz, he asked Chew if he knows “what happened in Tiananmen Square in 1989”, alleging that the China-owned app censors related content. He also asked Chew if he believes Chinese president Xi Jinping is a dictator. “I’m not going to comment on any world leaders, it’s not appropriate,” Chew said. Cotton responded by questioning if Chew believes he would lose his job if he says anything negative about the Chinese Communist party. “Are you scared that you’ll be arrested and disappeared the next time you go to mainland China?” he asked. Cottton pointedly asked Chew “of what nation are you a citizen?” and if he has ever applied for American or Chinese citizenship. The TikTok CEO replied, exasperated, that he is from Singapore. Chew repeatedly stated that content critical of China and “any other country” can be freely found on TikTok. Zuckerberg and Hawley spar over social media’s effects on mental health after Meta CEO says the science isn’t there Senator Josh Hawley targeted Mark Zuckerberg over claims in his opening statements that there is not scientific evidence that suggests there are widespread mental health impacts from social media. “I think it’s important to look at the science,” said Zuckerberg. “I know people widely talked about this as if that is something that’s already been proven, and I think that the bulk of the scientific evidence does not support that.” At the start of the hearing, Zuckerberg said, “The existing body of scientific work has not shown a causal link between using social media and young people having worse mental health.” Hawley cited Meta’s own internal research, leaked by Facebook whistleblower Frances Haugen, that showed Instagram has made body image issues worse for one in three girls. Another Facebook study of teenagers in the UK and the US, more than 40% of Instagram users who said they felt “unattractive” said the feeling began while using the app. “Your own study says that you make life worse for one in three teenage girls, and you’re here testifying to us in public that there’s no link,” he said. “For years you’ve been coming in public and testifying under oath that there’s absolutely no link, while internally you know full well your product is a disaster for teenagers.” Following an intense line of questioning with Mark Zuckerberg, Republican senator Josh Hawley asked the Meta executive if he would like to apologize to families of victims who are sitting in the audience of today’s Senate hearing, many of whom hold photos of children they say died or were harmed due to his platform. Zuckerberg stood up from the microphone, turned around to face the audience, and began to speak. “I’m sorry for everything you have all been through,” he said. “No one should go through the things that your families have suffered and this is why we invest so much and we are going to continue doing industry wide efforts to make sure no one has to go through the things your families have had to suffer.” US police prevented from viewing many online child sexual abuse reports, lawyers say Social media firms relying on AI for moderation generate unviable reports which prevent authorities from investigating cases Social media companies relying on artificial intelligence software to moderate their platforms are generating unviable reports on cases of child sexual abuse, preventing US police from seeing potential leads and delaying investigations of alleged predators. The Guardian has previously reported that Meta was accused of not having done enough to safeguard children following the death of a teenager in the UK. Whistleblower Arturo Béjar said the social media company already has the infrastructure in place to shield teenagers from harmful content. Béjar, a former senior engineer and consultant at the Instagram and Facebook owner, said if the company had learned its lessons from Molly Russell’s death and subsequent inquest it would have created a safer experience for young users. You can read our reporting here: Ted Cruz is screaming at Mark Zuckerberg over child abuse content on Instagram. He noted that if users search for hashtags related to CSAM (Child Sexual Abuse Material) the platform warns users that the content may be illegal and gives them the option to click through and see it. “Mr Zuckerberg, what the hell were you thinking?” Cruz yelled during the hearing. Cruz asked how many times this warning screen has been served to users. Zuckerberg said he did not know but will “personally look into this” and follow up with the committee. Here’s a video clip of the tense exchange between Graham and Zuckerberg: Senator Lindsey Graham targeted Meta CEO Mark Zuckerberg with questions about a teenage Instagram user who died by suicide after being targeted by a sextortion ring via the platform, asking the executive if he believes the family of the victim should be able to sue the company. “I think that they can,” Zuckerberg responded. Graham retorted that such lawsuits are often thrown out due to section 230, and promoted bipartisan legislation that would more easily allow victims to take companies to court. In a tense line of questioning, the Republican senator asked top tech executives if they supported such legislation, and noted that they refused to answer directly with a “yes” or “no”. “The bottom line, I’ve come to conclude, is that you aren’t going to support any of this,” he said. “If you’re waiting on these guys to solve the problem, we’re going to die waiting.” In her opening statements before Congress, X chief executive officer Linda Yaccarino said the company endorses the Stop CSAM Act, a bill introduced by Sen. Dick Durbin (D-IL) that would remove legal immunity for civil claims against internet companies over child sex abuse material. “You have my personal commitment that X will be active and a part of this solution,” Yaccarino said. “X believes that the freedom of speech and platform safety can and must coexist. We agree that now is the time to act with urgency.” Durbin thanked her for being the “first social media company” to publicly endorse the act. “It is our honor, chairman,” she replied. Yaccarino said in her opening remarks that X had bolstered its resources for dealing with child sexual abuse material, though how much is unclear: Elon Musk reduced the size of the company by more than half, including its trust and safety teams. Yaccarino stopped short of endorsing the Kids Online Safety Act (Kosa), another bill meant to target section 230 immunity for social media firms that was recently endorsed by the Snapchat parent company. But she said X “supports the progress” of the bill. Snap’s Evan Spiegel has endorsed the measure. Kosa and the Stop CSAM act have been flagged by civil and digital rights groups for potential privacy and freedom-of-speech violations, due in part to their targeting of encryption tools as well as potential use of such bills to target LGBTQ content misidentified as dangerous. Arturo Béjar, a former senior engineer and consultant at Meta who testified in Washington in November about what he described as child safety failings at the company. He said emails released in advance of the hearing showed executives and Zuckerberg failing to act on issues like suicide ideation. “If this work was a priority, there would be a thousand engineers and product managers on well-being. This is a company with over 30,000 engineers,” he told the Guardian. Mark Zuckerberg was asked for more resources to increase teen wellbeing on his platforms by senior lieutenant Sir Nick Clegg in 2021, according to emails released by Sen. Richard Blumenthal (D-CT) ahead of Wednesday’s hearing. Clegg, then vice‑president for global affairs and communications at the Facebook and Instagram owner, asked for more investment in August 2021 to “strengthen our position on well-being across the company.” he said the matter was becoming urgent as “politicians in the US, UK, EU and Australia are publicly and privately expressing concerns about the impact of our products on young people’s mental health.” He said the company’s efforts on addressing wellbeing concerns among users was “being held back by a lack of investment”. In one reply to Clegg, Sheryl Sandberg, then chief operating officer at Meta, said she was “supportive” of the investment request but “we have overall budgeting issues across the board so no promises on what will happen.” “The hypocrisy is mind-boggling,” Blumenthal told The New York Times. “We’ve heard time and time again how much they care and are working on this, but the documents show a very different picture.” In response to criticism of its efforts to safeguard children’s well-being, Meta has said it employs 40,000 people to improve trust and safety and has invested $20bn in such efforts since 2016. A Meta spokesperson said: “These cherry-picked documents do not provide the full context of how the company operates or what decisions were made.” The congressional hearing investigating online sexual and other exploitation of children is under way, with executives from Meta, X, TikTok, Snap, and Discord sharing prepared statements. Ahead of the statements, Sen. Dick Durbin (D-IL) noted that Mark Zuckerberg of Meta and Shou Zi Chew of TikTok were appearing voluntarily, whereas Linda Yaccarino of X (formerly Twitter), Evan Spiegel of Snap, and Jason Citron of Discord had to be subpoenaed and forced to appear. “I hope this is not a sign of your commitment or lack of commitment to addressing serious issue before us,” he said. After being sworn in, the executives began their testimonies, focusing largely on what tools their platforms have released to protect kids online. Many of them mentioned their own children and expressed their commitment to protecting kids online. “All of us here on this panel today throughout the tech industry have a solemn and urgent responsibility to ensure that everyone who uses our platform is protected from these criminals, both online and off,” Citron said in his opening statements. Zuckerberg stated that Meta has introduced more than 30 such tools over the last eight years, including controls that let parents set time limits for app usage and see who their children are following and engaging with online. He added that Meta has spent $20bn on safety and security since 2016 and employs about 40,000 people to address such concerns. “We build technologies to tackle the worst online risks and share it to help our whole industry get better,” he said. Zuckerberg sought to shift more responsibility for children’s safety online to Apple and Google, which operate the world’s biggest app stores. His company made a similar point last year when it called for legislation that would require parental approval for app purchases and downloads by teens. Shou Zi Chew of TikTok cited the app’s “robust community guidelines”, including family pairing tools like setting screen time limits and filtering out certain content. He stated TikTok has more than 40,000 trust and safety professionals and expect to invest more than $2bn in trust and safety efforts in 2024 alone. “Keeping kids safe online requires a collaborative effort as well as collective action,” he said. “We’ve shared the community’s concern and commitment to protect young people online. We welcome the opportunity to work with you on legislation to achieve this goal.” Evan Spiegel of Snap, like other executives, acknowledged the victims of online harms in the room and parents of children who have been impacted by online harms. “Words cannot begin to express the profound sorrow. I feel that a service you designed to bring people happiness and joy has been abused to cause harm,” he said. “I want to be clear that we understand our responsibility to keep our community safe.” Family members of children who killed themselves after online sexual exploitation are attending the congressional hearing with portraits in hand. The mood in the room is tense and somber. Dozens of family members of victims are in the audience, holding up their loved one’s photos, hoping to catch the attention of the CEOs are they filed into the room flanked by staff. One woman quietly wept into her handkerchief. They have applauded senators’ jibes at the tech CEOs multiple times. One opening remark by Durbin elicited laughter: “Coincidentally, some of these platforms have implemented common-sense child safety protections within the last week.” In opening statements at Wednesday’s hearing, Sen. Lindsey Graham (R-SC) referenced parents and children in attendance, many of whom brought photos of their children they say died or suffered emotional damage as a result of social media. “To all the victims who came and showed us photos of your loved ones don’t quit, you’re making a difference,” he said. “Hopefully we can take your pain and turn it into something positive.” Like Senator Dick Durbin, Graham took aim at the legal immunity that Section 230 allows social media firms, stating it is “now time to repeal” the measure. “They’re destroying lives, and threatening democracy itself. These companies must be reined in, or the worst is yet to come,” he said. Referencing the chief executives in attendance, he said: “I know you don’t mean it to be so, but you have blood on your hands.” His statements drew applause from attendees, a rare riotous moment for a Congressional hearing from a passionate crowd. Before CEOs began their testimony, Durbin requested that attendees do not stand, shout, or applaud witnesses. “We have a large audience, the largest I’ve seen in this room,” he said. “I know there is high emotion in this room, for justifiable reasons. But I asked you to please follow the traditions of the committee.” Meta’s new parental tools will not protect vulnerable children, experts say Tech firm gives parents greater control over their children’s online activities, but not all kids have consistent supervision Meta introduced new parental supervision tools in July, but child protection and anti-sex trafficking organizations say the new measures offer little protection to the children most vulnerable to exploitation, and divert the responsibility from the company to keep its users safe. Meta estimates about 100,000 children using Facebook and Instagram receive online sexual harassment each day, including “pictures of adult genitalia”, according to internal company documents made public as part of a lawsuit by the New Mexico attorney general. A Senate judiciary committee hearing on Wednesday exploring how social media firms allegedly fail to protect their youngest users opened with a video featuring voices of children who described being were sexually exploited online. They said they were sexually exploited on Facebook, Instagram, X, and other platforms. The video also featured parents who say their children killed themselves following sexual exploitation online. “Big tech failed to protect me from online sexual exploitation,” one child said in the video. “We need Congress to do something for our children and protect them,” a parent said. In opening statements, Senator Dick Durbin said online child sexual exploitation is “a crisis in America”. He said executives in attendance on Wednesday represent tech companies that are “responsible for many of the dangers our children face online.” In attendance at the hearing are Mark Zuckerberg of Meta, Linda Yaccarino of X (formerly Twitter), Shou Zi Chew of TikTok, Evan Spiegel of Snap, and Jason Citron of Discord. “Their design choices, their failures to adequately invest in trust and safety, their constant pursuit of engagement and profit over basic safety of all put our kids and grandkids at risk,” Durbin said. The Senator called for legislation to address the harms, targeting section 230 of the Communications Decency Act, a law that exempts social media firms from legal liability for content and activity on their platforms. “Let this hearing be a call to action we need to get kids online safety legislation to the president’s desk,” Durbin said. US surgeon general issues advisory on ‘profound’ risks of child social media use Dr Vivek Murthy called on tech companies and policymakers to take ‘immediate action’ to protect children’s mental health in May Social media use by children and teenagers can pose a “profound risk of harm” to their mental health and wellbeing, the US surgeon general is warning. Murthy said that in the absence of robust independent research it is impossible to know whether social media is safe for children and adolescents. “The bottom line is we do not have enough evidence to conclude that social media is, in fact, sufficiently safe for our kids. And that’s really important for parents to know,” he said. Our two-year investigation suggests that the tech giant Meta is struggling to prevent criminals from using its platforms to buy and sell children for sex. Read more here: ‘The tide has turned’: why parents are suing US social media firms after their children’s deaths Social media firms have faced scrutiny from Congress over their impact on young users, but parents who have lost kids to online harm are now leading the charge ‘Fundamentally against their safety’: the social media insiders fearing for their kids Parents working for tech companies have a first-hand look at how the industry works – and the threats it poses to child safety “I really can’t imagine a world where, as things stand today, these things are safe for a 13-year-old to use,” Arturo Bejar told the Guardian. Bejar left Facebook in 2015, where he spent six years making it easier for users to report when they had problems on the platform. But it wasn’t until his departure that he witnessed what he described in recent congressional testimony as the “true level of harm” the products his former employer built are inflicting on children and teens – his own included. He discovered his then 14-year-old daughter and her friends were routinely subjected to unwanted sexual advances, harassment and misogyny on Instagram, according to his testimony. Chief executives from five major social media firms arrived in Congress on Wednesday morning to face questioning about alleged harms to young users caused by their platforms. The hearing, titled “Big Tech and the Online Child Sexual Exploitation Crisis”, promises to “examine and investigate the plague of online child sexual exploitation”, according to a statement from the US Senate Judiciary Committee. In attendance are chief executive officers including Mark Zuckerberg of Meta, Linda Yaccarino of X (formerly Twitter), Shou Zi Chew of TikTok, Evan Spiegel of Snap, and Jason Citron of Discord. In a speech on Tuesday preceding the hearing, Senator Dick Durbin said combating dangers faced by children online has been one of his “top priorities” as chair of the committee and said he plans to ask executives “what they’re doing to make their platforms inaccessible to child sex offenders”. “As recently as last week, some have launched new child safety measures that are long overdue, but it should not take a hearing before the Senate Judiciary Committee to finally get these companies to prioritize child safety,” he said. “Because these changes are half measures at best, I welcome the opportunity to question them about what more needs to be done.” Executives appearing in Congress are expected to highlight controls and tools introduced to manage children’s online experiences and mitigate harm. In prepared remarks, Zuckerberg stated that Meta has introduced more than 30 such tools over the last eight years, including controls that let parents set time limits for app usage and see who their children are following and engaging with online. He added that Meta has spent $20bn on safety and security since 2016 and employs around 40,000 people to address such concerns. “We’re committed to protecting young people from abuse on our services, but this is an ongoing challenge,” he said. “As we improve defenses in one area, criminals shift their tactics, and we have to come up with new responses.”</p>
</body>
</html>