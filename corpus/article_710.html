<!DOCTYPE html>
<html>
<head>
<title>Taylor Swift AI images prompt US bill to tackle nonconsensual, sexual deepfakes</title>
<meta charset="UTF-8">
    <style>
        body {
            font-family: Arial, sans-serif;
        }
    </style>
    </head>
<body>
<h1>Taylor Swift AI images prompt US bill to tackle nonconsensual, sexual deepfakes</h1>
<p>Publication Date: 2024-01-31</p>
<p>Author: Blake Montgomery</p>
<p>Section: Technology</p>
<p>Tags: Deepfake, Taylor Swift, Artificial intelligence (AI), Politics and technology, X, news</p>
<p>Article URL: <a href='https://www.theguardian.com/technology/2024/jan/30/taylor-swift-ai-deepfake-nonconsensual-sexual-images-bill' target='_blank'>https://www.theguardian.com/technology/2024/jan/30/taylor-swift-ai-deepfake-nonconsensual-sexual-images-bill</a></p>
<img src='https://media.guim.co.uk/2b2d3c5637ec689c3322ce2ae98cbd51e185b2ca/0_0_5500_3300/500.jpg' alt='Article Image'>
<p>A bipartisan group of US senators introduced a bill on Tuesday that would criminalize the spread of nonconsensual, sexualized images generated by artificial intelligence. The measure comes in direct response to the proliferation of pornographic AI-made images of Taylor Swift on X, formerly Twitter, in recent days. The measure would allow victims depicted in nude or sexually explicit “digital forgeries” to seek a civil penalty against “individuals who produced or possessed the forgery with intent to distribute it” or anyone who received the material knowing it was not made with consent. Dick Durbin, the US Senate majority whip, and senators Lindsey Graham, Amy Klobuchar and Josh Hawley are behind the bill, known as the Disrupt Explicit Forged Images and Non-Consensual Edits Act of 2024, or the “Defiance Act.” “This month, fake, sexually-explicit images of Taylor Swift that were generated by artificial intelligence swept across social media platforms. Although the imagery may be fake, the harm to the victims from the distribution of sexually-explicit ‘deepfakes’ is very real,” Durbin said in a press release. Sexualized, exaggerated images of Swift at football games went viral over the weekend on X, racking tens of millions of views, according to Twitter’s metrics. AI-made images or videos of real people, commonly known as “deepfakes”, have become increasingly common on the internet as the barrier to entry for creating them lowers, a product of the boom in artificial intelligence of recent years. Some remove a person’s clothes or superimpose a person’s face over another’s to depict them saying something they did not; some are entirely generated by AI. The images of Swift were probably made using Microsoft Designer and shared first on Telegram, 404 Media reported. Microsoft introduced changes to close the technical loophole that allowed for the creation of the images. “Nobody – neither celebrities nor ordinary Americans – should ever have to find themselves featured in AI pornography. Innocent people have a right to defend their reputations and hold perpetrators accountable in court. This bill will make that a reality,” said Hawley. Swifties, as the artist’s fans are known, began flooding X with tweets of the phrase “Taylor Swift AI” accompanied by clips of her performing to stymie searches for the images. Later, as bad press mounted, Elon Musk’s X took the drastic step of prohibiting all searches for Swift to contain the spread of the images. Musk laid off the majority of the employees responsible for curbing his social network’s worst impulses after he purchased the company for $44bn.</p>
</body>
</html>