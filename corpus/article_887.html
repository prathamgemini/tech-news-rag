<!DOCTYPE html>
<html>
<head>
<title>Google considering charge for internet searches with AI, reports say </title>
<meta charset="UTF-8">
    <style>
        body {
            font-family: Arial, sans-serif;
        }
    </style>
    </head>
<body>
<h1>Google considering charge for internet searches with AI, reports say </h1>
<p>Publication Date: 2024-04-04</p>
<p>Author: Alex Hern</p>
<p>Section: Technology</p>
<p>Tags: Artificial intelligence (AI), Search engines, Google, Computing, ChatGPT, OpenAI, Bing, news</p>
<p>Article URL: <a href='https://www.theguardian.com/technology/2024/apr/04/google-set-to-charge-for-internet-searches-with-ai-reports-say' target='_blank'>https://www.theguardian.com/technology/2024/apr/04/google-set-to-charge-for-internet-searches-with-ai-reports-say</a></p>
<img src='https://media.guim.co.uk/aa4cda3475f7f4d40276c7449700728d6afbd799/656_813_2984_1790/500.jpg' alt='Article Image'>
<p>Google is reportedly drawing up plans to charge for AI-enhanced search features, in what would be the biggest shake-up to the company’s revenue model in its history. The radical shift is a natural consequence of the vast expense required to provide the service, experts say, and would leave every leading player in the sector offering some variety of subscription model to cover its costs. Google’s proposals, first reported by the Financial Times, would entail the company exclusively offering its new search feature to users of its premium subscription services, which customers already have to sign up to if they want to use artificial intelligence assistants in other Google tools such as Gmail and its office suite. With that search experience, being trialled in beta for selected users, Google’s generative AI is used to respond to queries directly with a single answer, in a similar style to the conversational approach of ChatGPT and competitors. “AI search is more expensive to compute than Google’s traditional search processes. So in charging for AI search Google will be seeking to at least recoup these costs,” said Heather Dawe, chief data scientist at the digital transformation consultancy UST. Much of the focus within AI is on the huge expense of the computing power used to train cutting-edge generative models. In the last year Amazon ran a single training run that cost $65m (£51m), according to James Hamilton, an engineer, who expects, in the near future, the company to break the $1bn mark. Last week, OpenAI and Microsoft announced plans to build a $100bn datacentre for AI training, while in January Mark Zuckerberg said his goal was to spend at least $9bn just on Nvidia GPUs alone. But the cost of training AI is just a tenth of the total cost of the sector, according to the analyst Brent Thill at the investment firm Jefferies. Thill wrote in a briefing note: “The majority of AI compute spend today is directed to the running, not training, of models, and 90%+ of AI compute spend today is being directed towards inferencing [the process by which an AI model is queried], as inferencing spend has been growing much faster than training as more models and tools get put into production.” He added: “Some have priced new Gen AI features at a monthly rate, betting that higher charges will cover usage expenses, while others have priced on a per-usage basis to protect themselves on the cost-side. Some have also incorporated into existing plans, hoping to drive [user] growth.” Competitors in AI search offer similar subscription plans. Perplexity, an AI-powered search engine, runs no adverts but offers a $20 monthly “pro” tier that provides access to more powerful AI models and unlimited use. Others, though, continue to offer their products at a loss. The AI features in Microsoft’s Bing are free to use but tied to the company’s Edge browser. The browsing and search startup Arc offers its products free to users and says it intends to raise revenue in future by charging companies for business features.</p>
</body>
</html>