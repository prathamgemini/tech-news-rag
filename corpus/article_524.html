<!DOCTYPE html>
<html>
<head>
<title>Five takeaways from UK’s AI safety summit at Bletchley Park</title>
<meta charset="UTF-8">
    <style>
        body {
            font-family: Arial, sans-serif;
        }
    </style>
    </head>
<body>
<h1>Five takeaways from UK’s AI safety summit at Bletchley Park</h1>
<p>Publication Date: 2023-11-02</p>
<p>Author: Dan Milmo</p>
<p>Section: Technology</p>
<p>Tags: Artificial intelligence (AI), Computing, Consciousness, Rishi Sunak, Elon Musk, Kamala Harris, Ursula von der Leyen, features</p>
<p>Article URL: <a href='https://www.theguardian.com/technology/2023/nov/02/five-takeaways-uk-ai-safety-summit-bletchley-park-rishi-sunak' target='_blank'>https://www.theguardian.com/technology/2023/nov/02/five-takeaways-uk-ai-safety-summit-bletchley-park-rishi-sunak</a></p>
<img src='https://media.guim.co.uk/1a27f061c8455c778e969183d3a9d773a7ec155a/0_79_6089_3653/500.jpg' alt='Article Image'>
<p>Rishi Sunak has hailed this week’s artificial intelligence summit as a diplomatic breakthrough after it produced an international declaration to address risks with the technology, as well as a multilateral agreement to test advanced AI Models. Here are five things we have learned from the summit. The UK pulled off a diplomatic coup The prime minister spent diplomatic capital convening global leaders, tech executives, academics and civil society figures at Bletchley Park in Milton Keynes, the base for second world war codebreakers. Those attending included the US vice-president, Kamala Harris, the European Commission president, Ursula von der Leyen, award-winning computer scientists, executives at all the leading AI companies – and Elon Musk. Even if Emmanuel Macron and Joe Biden were among the no-shows, the gathering had political and commercial heft. Tino Cuéllar, the president of the Carnegie Endowment for International Peace, said it was a “remarkable achievement” in diplomatic terms. This was symbolised by the signing of an international declaration that recognised the need to address risks represented by AI development, backed by more than 25 countries and the EU. France will host the next full-blown AI safety summit in 2024 – guaranteeing that Sunak’s initiative will live on. The declaration was followed on the second day by confirmation of United Nations support for an expert AI panel akin to the Intergovernmental Panel on Climate Change and agreement from major tech companies to collaborate with governments in testing their advanced AI models before and after they are released. The US is a hard power in AI The White House made clear its power to set the AI agenda this week. Biden issued an executive order requiring tech firms to submit test results for powerful AI systems to the government before they are released to the public. Harris gave a speech about AI in London on day one of the summit and announced the establishment of an AI safety institute, echoing a similar announcement by Sunak last week. Ultimately, this was followed by a multi-nation announcement, by Sunak, of government testing of AI models. The UK tech secretary, Michelle Donelan, said she was unfazed by the US initiatives, pointing to the fact the majority of cutting-edge AI companies, such as the ChatGPT developer OpenAI, are based in the US. That remark underlined the fact that the US has commercial, as well as political, strength in AI. Elon Musk has the star power The world’s richest man attended the summit and brought glitz, as well as distraction, to the gathering. Sunak invited him to Downing Street for a streamed fireside chat and the Tesla CEO’s warning that AI was “one of the biggest threats to humanity” overshadowed more nuanced contributions. Some guests viewed the attendance of Musk, whose nascent AI venture xAI is nowhere near the scale of the bigger players, as an example of Fomo (fear of missing out). But his presence brought extra attention to the summit. Existential risk is divisive, but short-term risk is not The possibility that AI can wipe out humanity – a view held by less hyperbolic figures than Musk – remains a divisive one in the tech community. That difference of opinion was not healed by two days of debate in Buckinghamshire. But if there is a consensus on risk among politicians, executives and thinkers, then it focuses on the immediate fear of a disinformation glut. There are concerns that elections in the US, India and the UK next year could be affected by malicious use of generative AI. Nick Clegg, president of global affairs at Mark Zuckerberg’s Meta, said this week that existential fears were being overplayed but he was concerned about the immediate threat to democratic polls. “We have some things which we need to deal with now,” he said. Countries are moving at their own speeds Every delegation at Bletchley was keen to claim preeminence in AI regulation, from European diplomats noting they had started the regulatory process four years ago to Americans talking up the power of their new AI safety institute. While the EU is moving closer to passing its AI act, UK officials have made clear they do not think regulation is needed, or even possible at this stage given how fast the industry is moving. But most agree on the importance of international summits such as this one, not least to help define the problem different countries are trying to tackle. One official said: “What we need most of all from the international stage is a panel like the International Panel on Climate Change, which at least establishes a scientific consensus about what AI models are able to do.”</p>
</body>
</html>