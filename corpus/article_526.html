<!DOCTYPE html>
<html>
<head>
<title>The great powers signed up to Sunak’s AI summit – while jostling for position</title>
<meta charset="UTF-8">
    <style>
        body {
            font-family: Arial, sans-serif;
        }
    </style>
    </head>
<body>
<h1>The great powers signed up to Sunak’s AI summit – while jostling for position</h1>
<p>Publication Date: 2023-11-02</p>
<p>Author: Kiran Stacey</p>
<p>Section: Technology</p>
<p>Tags: Artificial intelligence (AI), Computing, Rishi Sunak, China, European Union, Europe, Asia Pacific, analysis</p>
<p>Article URL: <a href='https://www.theguardian.com/technology/2023/nov/02/the-great-powers-signed-up-to-sunaks-ai-summit-while-jostling-for-position' target='_blank'>https://www.theguardian.com/technology/2023/nov/02/the-great-powers-signed-up-to-sunaks-ai-summit-while-jostling-for-position</a></p>
<img src='https://media.guim.co.uk/bcd3358db2607da70a79c577f1dd6d60e1d25bcd/0_267_4000_2399/500.jpg' alt='Article Image'>
<p>Sitting in a purpose-built hut in the grounds of the historic Bletchley Park country estate, British officials believed they had pulled off a diplomatic coup. On stage in front of them was the UK’s technology secretary, Michelle Donelan, and behind her were high-level representatives from the US and China, together for the first time to discuss the international regulation of artificial intelligence. Even better, both countries were among 28 signatories to the “Bletchley declaration”, an agreement to work together on safety standards that may prevent AI systems turning on humanity. Rishi Sunak said on Thursday: “Some said we shouldn’t even invite China; others said that we could never get an agreement with them. Both were wrong. A serious strategy for AI safety has to begin with engaging all the world’s leading AI powers, and all of them have signed the Bletchley Park communique.” Delegates expressed delight that China was not only present, but playing a substantive role in discussions – even if officials from Beijing were not invited to attend the more sensitive discussions on day two. British officials, led by the veteran facilitator Jonathan Black and the technology investor Matt Clifford, spent weeks persuading Beijing to attend the summit and sign on to the communique, including allowing officials to attend both days of the summit. Behind the diplomatic back-slapping, however, there are signs the world’s major powers are jostling for position. Each wants to be pre-eminent when it comes to setting the rules for how AI will develop, conscious that doing so might also help tilt the balance in favour of their own domestic priorities and companies. Some UK officials had hoped to get international endorsement to use Britain’s AI taskforce as an international hub for testing new systems before they are released to the public. Instead, Gina Raimondo, the US commerce secretary, announced her government would develop its own such institute, and the two would work closely together. Joe Biden also issued his own executive order on AI just days before the summit began – though British diplomats said this had helped focus discussions at Bletchley. The EU, meanwhile, is already well advanced in developing its own new AI regulations. Věra Jourová, the European Commission’s vice-president for values and transparency, said the UK was falling behind by its “own decision”. Sunak argues it is too early for legislation. “How can we write laws that make sense for something that we don’t yet fully understand?” he said last week. Disagreements also exist over what should happen with open-source AI, which allows anyone to use and develop new models. The British and American governments are worried this could empower people to cause large-scale social harm, whereas the French are far more enthusiastic about its possibilities. Yann LeCun, the French AI pioneer and chief AI scientist at Meta, Facebook’s parent company, is a vocal proponent of open-source. “There are some countries – including some in the European Union, France among them, and some in the global south – that are interested more generally in the availability of this technology to multiple countries,” said Tino Cuellar, president of the Carnegie Endowment for International Peace, who attended the summit. Nevertheless, officials from several countries believe they are laying the groundwork for a system that can knit together various domestic forms of regulation. Sunak announced on Thursday that countries around the world had agreed to set up a global panel of scientists to determine what AI can actually do, along the lines of the Intergovernmental Panel on Climate Change. Companies have also agreed to allow governments to vet their most advanced models for safety, though this will not be compulsory. Some compare the likely new system to air traffic control rules, where certain minimum standards are accepted across the developed world but countries are free to insist on stricter standards. Others speak of building something more like the drug approvals process, where certain countries accept the decisions made by each other’s regulators. Those in the main summit venue on Thursday described it being half full, with many high-level guests, including Justin Trudeau, the prime minister of Canada, deciding to dial in remotely. But many in the industry were delighted just to see world leaders discussing the threats they have been warning about privately, and in some cases publicly, for years. Max Tegmark, a key figure in the campaign to pause advanced AI development, said: “I’ve been working for about 10 years, hoping that one day there would be an international summit on AI safety. Seeing it actually happen with my own eyes – and done so surprisingly well – was actually very moving.”</p>
</body>
</html>